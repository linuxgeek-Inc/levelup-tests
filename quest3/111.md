##### 제한된 용량의 Docker에서 파일 용량의 오류가 날 때는?#####

**1-1) Docker 서비스 중지**
```bash
systemctl stop docker
```

```tech
systemctl
```
```desc
#### ⏹️ Docker 서비스 중지하기
`systemctl`을 사용하여 실행 중인 Docker 서비스를 안전하게 중지합니다.

- **`systemctl stop`**: 서비스를 중지하는 명령어
- **`docker`**: 제어할 서비스의 이름

> 💡 Docker 설정을 변경하거나 데이터를 직접 수정하기 전에는 반드시 서비스를 먼저 중지해야 합니다.
```

**1-2) 도커 PID 파일 및 데이터 삭제**
```bash
rm -f /var/run/docker.pid && rm -rf /xfs_quota/dockerdata/*
```

```tech
rm
```
```desc
#### 🗑️ 기존 Docker 데이터 정리하기
`rm` 명령어를 사용하여 Docker의 PID 파일과 이전에 사용하던 데이터 디렉터리의 모든 내용을 삭제합니다.

- **`rm -f`**: 파일을 강제로 삭제
- **`rm -rf`**: 디렉터리와 그 안의 모든 내용을 강제로 삭제
- **`&&`**: 앞 명령이 성공하면 뒤 명령을 실행

> ⚠️ 이 명령어는 기존 Docker 데이터를 모두 삭제하므로, 중요한 데이터가 없는지 확인 후 실행해야 합니다.
```

**1-3) 도커 데몬 수동 실행 (데이터 루트 지정)**
```bash
nohup dockerd --data-root=/xfs_quota/dockerdata > /var/log/dockerd.log 2>&1 &
```

```tech
nohub
```
```desc
#### 🚀 Docker 데몬 수동 실행하기
새로운 데이터 경로를 지정하여 Docker 데몬을 백그라운드에서 수동으로 실행합니다.

- **`nohup`**: 터미널이 종료되어도 프로세스가 계속 실행되도록 함
- **`dockerd`**: Docker 데몬(서버) 프로세스
- **`--data-root`**: Docker가 데이터를 저장할 경로를 지정
- **`> ... 2>&1 &`**: 모든 출력(표준, 에러)을 로그 파일로 보내고 백그라운드에서 실행

> 💡 Docker의 기본 저장 공간이 아닌 다른 경로를 사용하고 싶을 때 이 방법을 사용합니다.
```


**2-1) 도커 컨테이너 실행시 스토리지 용량 제한**
```bash
docker run -it -d --storage-opt size=2G --name xfstest2g ubuntu:22.04
```
```no-err-check
unable
```
```tech
docker
```
```desc
#### 📦 2GB 용량 제한 컨테이너 생성하기
`docker run` 명령어로 2GB의 저장 공간 크기 제한을 가진 새로운 Ubuntu 컨테이너를 생성하고 실행합니다.

- **`docker run`**: 새 컨테이너를 실행하는 명령어
- **`-it -d`**: 터미널 연결을 유지하고(-it) 백그라운드에서(-d) 실행
- **`--storage-opt size=2G`**: 컨테이너의 최대 디스크 크기를 2GB로 제한
- **`--name xfstest2g`**: 컨테이너의 이름을 `xfstest2g`로 지정

> 💡 컨테이너별로 용량을 제한하면 특정 컨테이너가 서버의 모든 디스크를 사용하는 것을 방지할 수 있습니다.
```

**2-2) 컨테이너 진입**
```bash
docker exec -it xfstest2g bash
```

```tech
docker
```
```desc
#### 🚪 컨테이너 내부로 들어가기
`docker exec` 명령어를 사용하여 실행 중인 컨테이너 내부의 셸(`bash`)에 접속합니다.

- **`docker exec`**: 실행 중인 컨테이너 안에서 명령을 실행
- **`-it`**: 상호작용이 가능한 터미널 모드로 접속
- **`xfstest2g`**: 접속할 컨테이너의 이름
- **`bash`**: 실행할 명령어 (배시 셸)

> 💡 컨테이너 내부에 들어가면 마치 별도의 작은 리눅스 서버에 접속한 것처럼 작업할 수 있습니다.
```

**3-1) 작업 디렉터리 생성**
```bash
mkdir /workspace
```

```tech
mkdir
```
```desc
#### 📁 작업 폴더 만들기
`mkdir` 명령어로 컨테이너 내부에 파일을 저장할 `workspace`라는 새 디렉터리를 만듭니다.

- **`mkdir`**: 디렉터리를 생성하는 명령어
- **`/workspace`**: 생성할 디렉터리의 이름과 경로

> 💡 파일을 체계적으로 관리하기 위해 작업용 폴더를 만드는 것이 좋습니다.
```

**3-2) 작업 디렉터리 이동**
```bash
cd /workspace
```

```tech
cd
```
```desc
#### 🚶 작업 폴더로 이동하기
`cd` 명령어로 방금 만든 `/workspace` 디렉터리로 현재 위치를 변경합니다.

- **`cd`**: 디렉터리를 변경하는 명령어

> 💡 이후의 모든 파일 작업은 이 `workspace` 폴더 안에서 이루어집니다.
```

**4)  패키지 리스트 업데이트 및 wget 설치**
```bash
apt update && apt install -y wget
```
```no-err-check
```
```tech
apt
```
```desc
#### 🔄 패키지 목록 업데이트 및 `wget` 설치
`apt` 패키지 관리자를 사용하여 패키지 목록을 최신화하고, 파일 다운로드에 필요한 `wget` 도구를 설치합니다.

- **`apt update`**: 설치 가능한 패키지 목록을 새로고침
- **`apt install -y wget`**: `wget` 패키지를 자동으로 'yes'하며 설치

> 💡 Ubuntu/Debian 기반 컨테이너에서는 새로운 프로그램을 설치하기 전에 `apt update`를 먼저 실행하는 것이 좋습니다.
```

**5-1) 모델 다운로드**
```bash
wget https://huggingface.co/gpt2-medium/resolve/main/pytorch_model.bin -O /workspace/gpt2-medium.bin
```

```tech
wget
```
```desc
#### 📥 모델 파일 다운로드하기
`wget`을 사용하여 대용량 모델 파일을 웹에서 다운로드하여 `workspace` 폴더에 저장합니다.

- **`wget`**: URL을 통해 파일을 다운로드하는 명령어
- **`-O`**: 다운로드한 파일의 이름과 저장 경로를 지정

> 💡 이 파일은 컨테이너의 용량 제한을 테스트하기 위해 사용됩니다.
```

**5-2) 영상 다운로드 ( 오류 발생 )**
```bash
wget http://xcal1.vodafone.co.uk/1GB.zip -O /workspace/sample_video_1GB.zip
```
```fail-pass
```
```tech
wget
```
```desc
#### 💥 용량 초과 오류 발생시키기
1GB 크기의 샘플 파일을 추가로 다운로드하여 컨테이너의 저장 공간(2GB)을 초과시켜 의도적으로 오류를 발생시킵니다.

- **`wget ...`**: 대용량 파일 다운로드 시도

> 💡 "No space left on device" (디스크에 남은 공간 없음) 오류가 발생하며, 설정한 용량 제한이 잘 동작함을 확인할 수 있습니다.
```



**6)현재 디렉터리의 디스크 사용량 확인.**
```bash
df -h .
```
- `df -h .` : 현재 폴더가 속한 파일시스템의 전체 용량과 남은 공간 확인
- `du -h .` : 각 파일과 폴더가 사용 중인 용량 간단히 확인
- `ls -lh /workspace` : /workspace 폴더 파일과 크기를 사람 읽기 좋은 단위로 표시

```tech
df
```
```desc
#### 💾 디스크 사용량 확인하기
`df` 명령어로 현재 디렉터리가 포함된 파일 시스템의 전체 용량, 사용된 용량, 남은 용량을 확인합니다.

- **`df`**: 디스크 여유 공간(Disk Free)을 보여주는 명령어
- **`-h`**: 사람이 읽기 쉬운 단위(GB, MB 등)로 표시
- **`.`**: 현재 디렉터리를 기준으로 확인

> 💡 컨테이너에 설정한 2GB 용량이 거의 다 사용된 것을 볼 수 있습니다.
```

**7-1) 현재 디렉토리에서 용량을 가장 많이 차지하는 파일들 확인.**
* 현재 디렉터리 내에서 용량이 큰 상위 10개 파일과 폴더를 크기 순으로 정렬해 보여줍니다.

- `ls -alh` : 숨김 파일 포함(-a), 상세 정보(-l), 사람이 읽기 좋은 단위(-h)로 출력.
- `sort -h` : 사람이 읽기 좋은 단위(K, M, G) 기준으로 정렬 (오름차순) 
- `head -10` : 상위 10개만 출력

```bash
ls -alh | sort -h | head -10
```

```tech
ls
```
```desc
#### 🐘 용량이 큰 파일 찾기
여러 명령어를 파이프(`|`)로 연결하여 현재 디렉터리에서 용량이 가장 큰 파일 10개를 찾아 목록으로 보여줍니다.

- **`ls -alh`**: 모든 파일의 정보를 자세히 출력
- **`sort -h`**: 파일 크기 순서로 정렬
- **`head -10`**: 정렬된 결과 중 상위 10개만 표시

> 💡 디스크 용량이 부족할 때 어떤 파일이 공간을 많이 차지하는지 빠르게 찾을 수 있는 유용한 방법입니다.
```

**7-2) 현재 디렉토리에서 오랫동안 사용 하지 않은 파일들을 확인.**
* 오래 사용하지 않은 파일을 찾아서 최근 접근 시간 순으로 정렬해 상위 10개를 보여줍니다.

- `find . -type f` : 현재 폴더 내 파일만 찾기  
- `stat -c '%X %n'` : 각 파일의 마지막 접근시간(UNIX timestamp)과 이름 출력  
- `2>/dev/null` : 에러 메시지 숨김  
- `sort -n` : 접근시간 기준 오름차순 정렬 (오래된 것부터)  
- `head -10` : 상위 10개만 출력  

```bash
find . -type f -exec stat -c '%X %n' {} + 2>/dev/null | sort -n | head -10
```

```tech
find
```
```desc
####  धूल 오래된 파일 찾기
`find`와 `stat` 명령어를 조합하여 오랫동안 접근하지 않은(사용한 적 없는) 파일을 찾아 오래된 순서대로 10개를 보여줍니다.

- **`find`**: 특정 조건의 파일을 검색
- **`stat`**: 파일의 상세 정보(접근 시간 등)를 출력
- **`sort -n`**: 숫자를 기준으로 정렬

> 💡 불필요한 파일을 정리할 때, 크기가 크면서 오랫동안 사용하지 않은 파일을 우선적으로 삭제하면 효율적입니다.
```

**8-1) 컨테이너 내부에서 종료**
```bash
exit
```

```tech
exit
```
```desc
#### 👋 컨테이너에서 나가기
`exit` 명령어를 입력하여 컨테이너 내부의 셸 세션을 종료하고 원래 호스트 머신의 터미널로 돌아갑니다.

- **`exit`**: 현재 셸을 종료

> 💡 컨테이너 자체는 백그라운드에서 계속 실행 중인 상태입니다.
```

**8-2) 기존 컨테이너 강제 삭제**
```bash
docker rm -f xfstest2g
```

```tech
docker
```
```desc
#### ❌ 컨테이너 강제 삭제하기
`docker rm` 명령어로 실행 중인 컨테이너를 강제로 삭제합니다.

- **`docker rm`**: 컨테이너를 삭제하는 명령어
- **`-f`**: 실행 중인 컨테이너라도 강제로 삭제하는 옵션
- **`xfstest2g`**: 삭제할 컨테이너의 이름

> 💡 용량 제한 테스트가 끝났으므로 기존 컨테이너를 정리합니다.
```

**8-3) 용량을 4GB로 늘려서 도커 생성**
```bash
docker run -it -d --storage-opt size=4G --name xfstest4g ubuntu:22.04
```
```no-err-check
unable
```
```tech
docker
```
```desc
#### 📦 4GB 용량 컨테이너 새로 생성하기
이번에는 저장 공간 크기를 4GB로 늘려서 새로운 컨테이너를 생성합니다.

- **`--storage-opt size=4G`**: 컨테이너의 최대 디스크 크기를 4GB로 제한
- **`--name xfstest4g`**: 새 컨테이너의 이름을 `xfstest4g`로 지정

> 💡 필요한 용량에 맞게 컨테이너를 다시 생성하여 문제를 해결하는 과정을 보여줍니다.
```

**8-4) 컨테이너 진입**
```bash
docker exec -it xfstest4g bash
```

```tech
docker
```
```desc
#### 🚪 새 컨테이너로 들어가기
`docker exec`를 사용하여 4GB 용량으로 새로 만든 `xfstest4g` 컨테이너의 내부 셸에 접속합니다.

- **`xfstest4g`**: 접속할 새 컨테이너의 이름

> 💡 이제 더 넓은 공간에서 파일 다운로드를 다시 시도할 수 있습니다.
```

**9-1) 작업 디렉터리 생성**
```bash
mkdir /workspace
```

```tech
mkdir
```
```desc
#### 📁 작업 폴더 다시 만들기
`mkdir` 명령어로 새 컨테이너 안에 `workspace` 디렉터리를 다시 생성합니다.

> 💡 새 컨테이너는 완전히 깨끗한 상태이므로 필요한 디렉터리를 다시 만들어야 합니다.
```

**9-2) 작업 디렉터리 이동**
```bash
cd /workspace
```

```tech
cd
```
```desc
#### 🚶 작업 폴더로 이동하기
`cd` 명령어로 `/workspace` 디렉터리로 이동하여 파일 작업을 준비합니다.
```

**9-3)  패키지 리스트 업데이트 및 wget 설치**
```bash
apt update && apt install -y wget
```
```no-err-check
```

```tech
apt
```
```desc
#### 🔄 `wget` 다시 설치하기
새 컨테이너에 `wget`이 없으므로 `apt`를 이용해 다시 설치합니다.

> 💡 컨테이너는 독립적인 환경이므로, 필요한 도구는 각 컨테이너마다 설치해주어야 합니다.
```

**10) 디스크 사용량 확인( df,du,ls 모두 이용해서 확인 가능)**
```bash
df -h .
```

```tech
df
```
```desc
#### 💾 늘어난 디스크 용량 확인하기
`df -h .` 명령어로 현재 컨테이너의 디스크 용량을 확인합니다.

> 💡 이제 전체 용량이 4GB로 늘어난 것을 확인할 수 있습니다.
```

**11-1) 모델 다운로드**
```bash
wget https://huggingface.co/gpt2-medium/resolve/main/pytorch_model.bin -O /workspace/gpt2-medium.bin
```

```tech
wget
```
```desc
#### 📥 모델 파일 다시 다운로드하기
`wget`으로 이전에 받았던 모델 파일을 다시 다운로드합니다.
```

**11-2) 샘플 영상 다운로드**
```bash
wget http://xcal1.vodafone.co.uk/1GB.zip -O /workspace/sample_video_1GB.zip
```

```tech
wget
```
```desc
#### ✅ 샘플 영상 다운로드 성공하기
이전에 용량 부족으로 실패했던 1GB 샘플 영상 파일을 다시 다운로드합니다.

> 💡 이제 컨테이너 용량이 4GB로 충분하기 때문에 오류 없이 다운로드가 성공적으로 완료됩니다.
```


**12-1) 현재 디렉토리에서 용량을 가장 많이 차지하는 파일들 확인.**
* 현재 디렉터리 내에서 용량이 큰 상위 10개 파일과 폴더를 크기 순으로 정렬해 보여줍니다.

- `ls -alh` : 숨김 파일 포함(-a), 상세 정보(-l), 사람이 읽기 좋은 단위(-h)로 출력.
- `sort -h` : 사람이 읽기 좋은 단위(K, M, G) 기준으로 정렬 (오름차순) 
- `head -10` : 상위 10개만 출력

```bash
ls -alh | sort -h | head -10
```

```tech
ls
```
```desc
#### 🐘 용량이 큰 파일 다시 확인하기
`ls`와 `sort`를 이용해 현재 디렉터리에서 어떤 파일이 용량을 많이 차지하는지 다시 확인합니다.

> 💡 다운로드한 두 개의 큰 파일이 목록 상위에 표시됩니다.
```

**12-2) 현재 디렉토리에서 오랫동안 사용 하지 않은 파일들을 확인.**
* 오래 사용하지 않은 파일을 찾아서 최근 접근 시간 순으로 정렬해 상위 10개를 보여줍니다.

- `find . -type f` : 현재 폴더 내 파일만 찾기  
- `stat -c '%X %n'` : 각 파일의 마지막 접근시간(UNIX timestamp)과 이름 출력  
- `2>/dev/null` : 에러 메시지 숨김  
- `sort -n` : 접근시간 기준 오름차순 정렬 (오래된 것부터)  
- `head -10` : 상위 10개만 출력  

```bash
find . -type f -exec stat -c '%X %n' {} + 2>/dev/null | sort -n | head -10
```

```tech
find
```
```desc
#### 📂 오래된 파일 다시 확인하기
`find`를 이용해 오래된 파일을 찾아 정리 대상을 물색합니다.

> 💡 지금은 모든 파일을 방금 다운로드했기 때문에 큰 의미는 없지만, 실제 운영 환경에서는 유용한 명령어입니다.
```


**13) 저장 공간 확인**
```bash
df -h .
```

```tech
df
```
```desc
#### 📊 최종 저장 공간 확인하기
`df -h .` 명령어로 모든 작업을 마친 후의 최종 디스크 사용량을 확인합니다.

> 💡 4GB 중 약 2.5GB를 사용하여 충분한 여유 공간이 남아있는 것을 볼 수 있습니다.
```
